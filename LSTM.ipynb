{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Lab06.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NbmTD19EKFp",
        "colab_type": "text"
      },
      "source": [
        "# Lab 06: Recurrent Neural Network (RNN)\n",
        "\n",
        "Trong bài thực hành này:\n",
        "- Cài đặt 1 mạng RNN cơ bản LSTM\n",
        "- Sử dụng Word Embedding GLOVE của Stanford\n",
        "- Chạy trên data spam detection\n",
        "\n",
        "Reference:\n",
        "- Glove: https://github.com/stanfordnlp/GloVe\n",
        "- LSTM: Long Short-Term Memory layer - Hochreiter 1997.\n",
        "\n",
        "Đọc thêm:\n",
        "- LSTM: https://colah.github.io/posts/2015-08-Understanding-LSTMs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7YwSOy8EKFt",
        "colab_type": "text"
      },
      "source": [
        "## Tiền xử lý dữ liệu\n",
        "\n",
        "Chúng ta cần tách câu thành từng từ trước."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2iNfNoFEPDc",
        "colab_type": "code",
        "outputId": "3deb03de-a4f2-48a1-d481-65a74fc1b83a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDDNX2KhEbWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path='gdrive/My Drive/DATASCIENCE/MayHocNangCao/Lab06/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwrGzzltEKFu",
        "colab_type": "code",
        "outputId": "993bdcf1-5e9c-401a-8abf-9c8aa147ca52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        }
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "df = pd.read_csv(path+\"spam_detection.csv\")\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>spam</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>ham</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Text Label  y\n",
              "0  Go until jurong point, crazy.. Available only ...   ham  0\n",
              "1                      Ok lar... Joking wif u oni...   ham  0\n",
              "2  Free entry in 2 a wkly comp to win FA Cup fina...  spam  1\n",
              "3  U dun say so early hor... U c already then say...   ham  0\n",
              "4  Nah I don't think he goes to usf, he lives aro...   ham  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKUim6E5EKFy",
        "colab_type": "code",
        "outputId": "d24dbccc-4719-48ed-99f7-4f91b0067df3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "texts = df[\"Text\"].to_list()\n",
        "texts = [text.lower() for text in texts]            # chuyển các đoạn text thành chữ thường (word embedding chỉ cho chữ thường)\n",
        "tokenized_texts = [nltk.tokenize.word_tokenize(text) for text in texts]   # tách câu thành một list các từ\n",
        "\n",
        "print(tokenized_texts[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ok', 'lar', '...', 'joking', 'wif', 'u', 'oni', '...']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5ZfPQEJEKF2",
        "colab_type": "text"
      },
      "source": [
        "## Load embedding từ file\n",
        "\n",
        "Pretrained Embeddings từ Glove-Stanford đã được rút gọn cho bài tập này và lưu thành file glove_embedding.txt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAN4GozgEKF3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## không cần hiểu đống này lắm đâu\n",
        "import io\n",
        "import numpy as np\n",
        "def load_word_embeddings(fname):\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    vocab, matrix = [], []\n",
        "    i=0\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        vocab.append(tokens[0])\n",
        "        matrix.append(list(map(float, tokens[1:])))\n",
        "    return vocab, np.asarray(matrix)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFUyCLAHEKF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab, matrix = load_word_embeddings(path+\"glove_embedding.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NhkIEkrFEKF9",
        "colab_type": "text"
      },
      "source": [
        "Sau khi đọc xong thì\n",
        "- vocab: một danh sách các từ vực có trong embedding\n",
        "- matrix: một ma trận, mỗi dòng là một embedding cho từ tương ứng trong vocab (xếp đúng thứ tự)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qW1CUJPfEKF-",
        "colab_type": "text"
      },
      "source": [
        "## Số hóa data\n",
        "\n",
        "Để số hóa 1 từ (word) trong ngôn ngữ tự nhiên, người ta sẽ biểu diễn từ đó thành một vector (gọi là embedding). 2 bước trước ta đã tách các câu trong data thành từ riêng biệt, và load một bộ embedding có sẵn. Bây giờ ta chuyển từng từ trong data thành một mã số biểu thị vị trí của từ đó trong ma trận embedding.\n",
        "\n",
        "Tuy nhiên, ta cần có vài mã số đặc biệt để giải quyết các vấn đề như: \n",
        "- từ không có trong embedding\n",
        "- Độ dài các câu không giống nhau. Cơ bản, các thư viện deep learning tính toán nhanh dựa trên các kĩ thuật tính toán ma trận (tensor), nên để tính các câu có độ dài ngắn khác nhau, các câu ngắn cần được nối thêm bởi các mã đặc biệt để có cùng kích thước.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3xsc9FZEKF_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Gán các mã\n",
        "__PADDED_INDEX__ = 0    # mã dùng cho các vị trí chỉ có tính nối dài cho cùng kích thước\n",
        "__UNKNOWN_WORD__ = 1    # mã cho những từ không có trong embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmW99aYNEKGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Tạo một dictionary, có nhiệm vụ là một ánh xạ từ ảnh sang mã số, mã số được bắt đầu từ 2 vì số 0 và 1 được dành cho trường hợp đặc biệt\n",
        "word_to_index = {word: index+2 for index, word in enumerate(vocab)}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nidJA8MEKGF",
        "colab_type": "code",
        "outputId": "76212381-3577-47ba-e306-ea8e323959eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "# Do do mã số được bắt đầu từ 2, nên cần thêm 2 vector vào đàu ma trận\n",
        "embedding_matrix = np.pad(matrix, [[2,0],[0,0]], mode='constant', constant_values =0.0)\n",
        "print(embedding_matrix)\n",
        "\n",
        "# Khi đó, __PADDED_INDEX__ dùng dòng đầu tiên của  embedding_matrix\n",
        "# __UNKNOWN_WORD__ dùng dòng thứ hai của embedding_matrix "
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.         0.         0.        ...  0.         0.         0.       ]\n",
            " [ 0.         0.         0.        ...  0.         0.         0.       ]\n",
            " [ 0.18378   -0.12123   -0.11987   ... -0.039038   0.18274    0.14654  ]\n",
            " ...\n",
            " [ 0.18754   -0.040832   0.19611   ...  0.079996   0.016479   0.17797  ]\n",
            " [-0.1167     0.0073071 -0.19401   ...  0.21549    0.015527   0.14948  ]\n",
            " [ 0.075198  -0.097452  -0.14505   ...  0.23842   -0.39966    0.14454  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGkEx8wkEKGI",
        "colab_type": "code",
        "outputId": "7f0d4328-64d7-4238-fe5f-9e0ca7159ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        }
      },
      "source": [
        "## Bây giờ ta sẽ chuyển data spam dection thành các mã số\n",
        "import tensorflow as tf\n",
        "\n",
        "X = []\n",
        "for text in tokenized_texts:\n",
        "    cur_text_indices = []\n",
        "    for word in text:\n",
        "        if word in word_to_index:\n",
        "            cur_text_indices.append(word_to_index[word])    ## map từ word sang index\n",
        "        else:\n",
        "            cur_text_indices.append(__UNKNOWN_WORD__)       ## gán unknown cho từ không có trong bộ glove\n",
        "    X.append(cur_text_indices)\n",
        "\n",
        "## pad data cho có cùng chiều dài\n",
        "X = tf.keras.preprocessing.sequence.pad_sequences(sequences=X,       # sequences: list các câu có độ dài không bằng nhau\n",
        "                                                  padding='post')    # vị trí pad là 'pre' (trước) hoặc 'post' (sau)\n",
        "\n",
        "y = df['y'].values   ## Label của bài toán, 0 là không phải spam, 1 là spam"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7OOb4SJQTwO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Chuyển label của bài toán\n",
        "\n",
        "int2label = {0: \"spam\", 1: \"ham\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXodi0IzEKGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Chia data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size= 0.2, random_state =0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkibz4bvEKGO",
        "colab_type": "text"
      },
      "source": [
        "## RNN trong tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4WR9ZbGEKGP",
        "colab_type": "code",
        "outputId": "84b30236-5ae0-4617-c92f-44f9d2208a3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        }
      },
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, LSTM, Bidirectional, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "inputs = Input(shape=(None,))                   ## None biểu thị kích thước không xác định của câu\n",
        "\n",
        "embed = Embedding(input_dim=embedding_matrix.shape[0],   ## Khai báo kích thước của vocab\n",
        "                 output_dim=embedding_matrix.shape[1],   ## Khai báo kích thước của embedding\n",
        "                  embeddings_initializer = tf.keras.initializers.Constant(value=embedding_matrix),  ## Khởi tạo cho embedding bằng ma trận có sẵn\n",
        "                  trainable=False,                       ## Không cần thiết train embedding\n",
        "                 mask_zero=True)(inputs)                 ## zero_mask: những vị trí có giá trị 0 không được tính toán, vì đó là giá trị thêm vào cho đủ độ dài mà thôi\n",
        "                                                         ##  (__PADDED_INDEX__ gán bằng 0)\n",
        "\n",
        "lstm = Bidirectional(LSTM(units=100,                          ## units: kích thước của hidden_state trong LSTM\n",
        "            return_sequences=False))(embed)      ## return_sequences: LSTM trả về toàn bộ  hay là trả về hidden_state cuối cùng\n",
        "\n",
        "dense = Dense(units=2, activation='softmax')(lstm)\n",
        "model = Model(inputs=inputs,\n",
        "              outputs=dense)\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "             loss='sparse_categorical_crossentropy',\n",
        "             metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py:3994: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, None)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, None, 300)         2208600   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 200)               320800    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 2)                 402       \n",
            "=================================================================\n",
            "Total params: 2,529,802\n",
            "Trainable params: 321,202\n",
            "Non-trainable params: 2,208,600\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXC787n0EKGS",
        "colab_type": "code",
        "outputId": "f1a0522a-1571-4aa6-b7d3-15bcb3ee5ec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        }
      },
      "source": [
        "# Checkpoint Callback\n",
        "mc = tf.keras.callbacks.ModelCheckpoint(filepath=\"lstm_spam.h5\", \n",
        "                                     monitor='val_loss',\n",
        "                                     mode='min', \n",
        "                                     verbose=0, \n",
        "                                     save_best_only=True)\n",
        "# Train\n",
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "         epochs=10,\n",
        "         callbacks=[mc])\n",
        "\n",
        "model.load_weights(\"lstm_spam.h5\")\n",
        "_, val_acc = model.evaluate(X_valid, y_valid)\n",
        "print(\"Accuracy on valid: \", val_acc)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 4459 samples, validate on 1115 samples\n",
            "Epoch 1/10\n",
            "4459/4459 [==============================] - 108s 24ms/sample - loss: 0.1160 - acc: 0.9617 - val_loss: 0.0617 - val_acc: 0.9794\n",
            "Epoch 2/10\n",
            "4459/4459 [==============================] - 107s 24ms/sample - loss: 0.0378 - acc: 0.9879 - val_loss: 0.0605 - val_acc: 0.9794\n",
            "Epoch 3/10\n",
            "4459/4459 [==============================] - 107s 24ms/sample - loss: 0.0243 - acc: 0.9935 - val_loss: 0.0418 - val_acc: 0.9865\n",
            "Epoch 4/10\n",
            "4459/4459 [==============================] - 106s 24ms/sample - loss: 0.0159 - acc: 0.9962 - val_loss: 0.0512 - val_acc: 0.9794\n",
            "Epoch 5/10\n",
            "4459/4459 [==============================] - 108s 24ms/sample - loss: 0.0112 - acc: 0.9969 - val_loss: 0.0437 - val_acc: 0.9865\n",
            "Epoch 6/10\n",
            "4459/4459 [==============================] - 109s 24ms/sample - loss: 0.0033 - acc: 0.9993 - val_loss: 0.0492 - val_acc: 0.9865\n",
            "Epoch 7/10\n",
            "4459/4459 [==============================] - 108s 24ms/sample - loss: 0.0014 - acc: 0.9998 - val_loss: 0.0510 - val_acc: 0.9883\n",
            "Epoch 8/10\n",
            "4459/4459 [==============================] - 108s 24ms/sample - loss: 0.0010 - acc: 0.9998 - val_loss: 0.0574 - val_acc: 0.9874\n",
            "Epoch 9/10\n",
            "4459/4459 [==============================] - 106s 24ms/sample - loss: 9.2688e-04 - acc: 0.9998 - val_loss: 0.0598 - val_acc: 0.9874\n",
            "Epoch 10/10\n",
            "4459/4459 [==============================] - 106s 24ms/sample - loss: 8.6291e-04 - acc: 0.9998 - val_loss: 0.0640 - val_acc: 0.9857\n",
            "1115/1115 [==============================] - 7s 6ms/sample - loss: 0.0418 - acc: 0.9865\n",
            "Accuracy on valid:  0.9865471\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgnSh77dJbjT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def message_to_array(texts):\n",
        "  texts = texts.lower().split(' ')            # chuyển các đoạn text thành chữ thường (word embedding chỉ cho chữ thường)\n",
        "  #print(texts)\n",
        "  tokenized_texts = [nltk.tokenize.word_tokenize(text) for text in texts]\n",
        "  \n",
        "  print(tokenized_texts)\n",
        " # text = text.lower().split(' ')\n",
        "\n",
        "  cur_text_indices = []\n",
        "  for text in tokenized_texts:\n",
        "    for word in text:\n",
        "        if word in word_to_index:\n",
        "            cur_text_indices.append(word_to_index[word])    ## map từ word sang index\n",
        "        else:\n",
        "            cur_text_indices.append(__UNKNOWN_WORD__)       ## gán unknown cho từ không có trong bộ glove\n",
        "\n",
        "           \n",
        "  return cur_text_indices"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qHKDDzjGYmo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_predict(text):\n",
        "  model.load_weights(\"lstm_spam.h5\")\n",
        "  #model.summary()\n",
        "  test = message_to_array(text)\n",
        "  print(test)\n",
        "  pred = model.predict(test)[0]\n",
        "  \n",
        "  return np.argmax(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuGQgmhsLwLI",
        "colab_type": "code",
        "outputId": "2095c48c-ccc4-42b6-feee-b0b4386712e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "text = 'wanna ask something? just send me a mess'\n",
        "print(model_predict(text))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['wan', 'na'], ['ask'], ['something', '?'], ['just'], ['send'], ['me'], ['a'], ['mess']]\n",
            "[4416, 2777, 639, 232, 39, 69, 645, 72, 8, 2688]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KS1iUdjZQ8FZ",
        "colab_type": "code",
        "outputId": "db94bffb-b84d-4da9-9b64-4ec51c0c27bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "text = \"Urgent! You have won our competition's prize!! Please call us now.\"\n",
        "print(model_predict(text))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['urgent', '!'], ['you'], ['have'], ['won'], ['our'], ['competition', \"'s\"], ['prize', '!', '!'], ['please'], ['call'], ['us'], ['now', '.']]\n",
            "[3743, 37, 5669, 30, 1169, 64, 1453, 22, 2303, 37, 37, 223, 298, 107, 97, 4]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5eQJ6NOQ9Wd",
        "colab_type": "code",
        "outputId": "7d2606ba-61ed-478f-e818-a7bb1bed21cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "text = \"Call me to get a free holiday now\"\n",
        "print(model_predict(text))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['call'], ['me'], ['to'], ['get'], ['a'], ['free'], ['holiday'], ['now']]\n",
            "[298, 72, 6, 80, 8, 128, 986, 97]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-01KPFpEKGV",
        "colab_type": "text"
      },
      "source": [
        "## Bài tập\n",
        "- Nghiên cứu sử dụng tf.keras.layers.Bidirectional trong model. Lưu lý: cập nhật lên tensorflow 2.0 để Bidirectional chạy đúng mask_zero.\n",
        "- Hãy viết một hàm\n",
        "```python\n",
        "def model_predict(text):\n",
        "    \n",
        "    return True/False\n",
        "```\n",
        "để đoán xem một đoạn text đưa vào có phải là tin nhắn spam không (các biến khác dùng global)\n",
        "- Tự điều chỉnh và train model (chỉnh lại train, valid, tiền xử lý, dùng word_embedding,... nếu muốn) rồi đoán xem các câu sau có phải spam không:\n",
        "    - \"wanna ask something? just send me a mess\"\n",
        "    - \"Urgent! You have won our competition's prize!! Please call us now.\"\n",
        "    - \"Call me to get a free holiday now\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFwyx88XEKGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}